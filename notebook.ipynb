{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability with Bayesian networks in Python\n",
    "\n",
    "## Gašper Štukelj\n",
    "### Munich Center for Mathematical Philosophy (MCMP) / Graduate school of Systemic Neurosciences (GSN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this all about?\n",
    "\n",
    "### ¤ Bootstraping Bayes' theorem to frequencies (numpy)\n",
    "### ¤ Creating and visualizing graphs (networkx)\n",
    "### ¤ Using graphs to represent probabilities and make inferences (pgmpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import style\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from IPython.display import Image\n",
    "import ipywidgets as widgets \n",
    "\n",
    "%matplotlib inline\n",
    "style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Gašper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gašper.who_are_you()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gašper.what_are_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gašper.what_do_you_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('graph.png', width=300)\n",
    "\n",
    "# A BN is a DAG - Directed acyclic graph (arrows have directions, and we can never start and end at the \n",
    "# same node just by following the direction of the edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bayes' theorem is what puts the B in the things Bayesian:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE P(H \\mid E) = \\dfrac{P(E \\mid H) \\cdot P(H)}{P(E)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the ease of exposition, say that 'H' stand for a specific hypothesis and 'E' stands for 'evidence' (data).\n",
    "# The right term is often called 'posterior' probability - BT gives an answer to a very simple question: \n",
    "# 'What is the probability of H, after I have observed (learned that) E?' We can see that this 'conditional' \n",
    "# probability is dependent on three different terms: two uncoditional or 'marginal' probabilities P(H) and \n",
    "# P(E) are often called 'prior' probabilities in this context, because they correspond to prior confidence we \n",
    "# had in (or probability we assigned to) the hypothesis being true P(H) and data/evidence being observed P(E).\n",
    "# The third term is also a conditional probability and it quantifies the strength with which our hypothesis \n",
    "# predicted that this evidence will be observed, that is 'how likely' the evidence was considered by the \n",
    "# hypothesis/theory before it was actually observed, hence the term is often called 'the likelihood'. One last\n",
    "# thing to note is that Bayes theorem tells us that everything else kept the same (fixing the other terms),\n",
    "# the posterior will be higher for the theory we considered more likely beforehand, or for the theory that \n",
    "# assigned more probabilitiy to the evidence, and last but not least the posterior will be higher if what we\n",
    "# observe is something we didn't considered to be likely (low P(E)). One intuitive consequence of the latter is\n",
    "# that the data for which we're completely certain, i.e. P(E)=1 and P(E|H)=1, will not change our beliefs in\n",
    "# the truth of the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's roll our digital yellow die n-times and count the observed values! Intuitively all the values should\n",
    "# occur roughly 1/6 of the time. However, we see that this is only the case for higher n. This shows us that\n",
    "# numerical simulations are warranted if we repeat the \"experiment\" sufficient amount of times.\n",
    "\n",
    "n = 10\n",
    "estimate = 1/6\n",
    "\n",
    "plt.hist(np.random.randint(low=1, high=7, size=n), bins=range(8), \n",
    "             align='left', rwidth=0.7, normed=True,color='gold')\n",
    "\n",
    "plt.hlines(estimate, xmin=0.5, xmax=6.5, linestyle='--', colors='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probabilities are values between 0 and 1, an 'impossible' event has a probability 0 and a 'certain' event \n",
    "# has probability 1. Probabilities have to sum up to one. Often this restrictions are introduced through the\n",
    "# choice of axiomatization of the probability theory.\n",
    "\n",
    "# I trust it is enough for us to accept this restrictions insofar as we want to use the numpy.random module!\n",
    "# Read the docstring of the numpy.random.choice function and play around with different values to see that \n",
    "# probabilities are indeed non-negative and sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(['a', 'b', 'c'], p=[0.3, 0.8, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bootstraping Bayes' theorem to frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have two dice. The blue one is very biased towards 2. The  yellow one is 'fair', that is, it shows all values equally likely. We will pick the the yellow die with probability $P(Y) = p$ and blue die with probability $P(B) = 1 - p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll roll 2 either if we choose a blue die and it rolls 2 or if we choose a green die and it rolls 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large P(2) = P(2, B) + P(2, Y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an example of really shabby notation, but it does cut a lot of visual noise. Once you get used to the\n",
    "# proper notation (see the end of the notebook), avoid writing things in such a bad manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can think of it as having a 'mixed' - green die, s.t. it behaves like the yellow die for the fraction of throws proportional to the $p$, and the rest of the time as the blue die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can rewrite $P(2,B)$ as $P(2 \\mid B) \\cdot P(B)$, and $P(2,Y)$ as $P(2 \\mid Y) \\cdot P(Y)$, so that we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This factorization actually follows from the standard definition of the conditional probability. It is \n",
    "# helpful to think of what happens in the extremes to get the intuitions going. If we set p=0, then the whole\n",
    "# right part of the sum is zero we expect the green die to behave just like the blue die, that is probability \n",
    "# of green die rolling 2 is equal to the probability of rolling two given that we have a blue day. Similarly \n",
    "# if we set the p=1, the green die should behave exactly like a yellow die. Hence, the closer the p will be to\n",
    "# 1 the more we expect the green die to behave like a yellow die, and closer the p is to 0 the more we expect\n",
    "# the green die to behave like a blue die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large P(2) = P(2 \\mid B) \\cdot P(B) + P(2 \\mid Y) \\cdot P(Y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define three different dice. The 'mixed' die, is just green die rolled p fraction of the time, and blue\n",
    "# die rolled (1-p) fraction of the time.\n",
    "\n",
    "# Notice that both dice, and the 'mixed' die are generated separately!\n",
    "\n",
    "yellow = lambda s: np.random.randint(low=1, high=7, size=s)\n",
    "blue = lambda s: np.random.choice([1,2,3,4,5,6], p=[0.12, 0.4, 0.12, 0.12, 0.12, 0.12], size=s)\n",
    "green = lambda s,p: np.append(yellow(int(n*p)), blue(int(n*(1-p))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we're rolling the dice n-times and counting the number of occurences of each of the possible values.\n",
    "# Try re-running the cell with different n, and then observe how the value of p affects the distributions of\n",
    "# the dice and their similarity. \n",
    "\n",
    "n = 10\n",
    "\n",
    "def plot_machine(p):\n",
    "    ax = plt.gca(projection='3d')\n",
    "    \n",
    "\n",
    "    ax.bar(np.arange(1,7), np.histogram(yellow(n), normed=True, bins=range(1,8))[0],\n",
    "           zs=1, zdir='y', alpha=0.9, color='yellow', label='P(2 | G)')\n",
    "\n",
    "    ax.bar(np.arange(1,7), np.histogram(blue(n), normed=True, bins=range(1,8))[0], \n",
    "           zs=3, zdir='y', alpha=0.7, color='blue', label='P(2 | B)')\n",
    "\n",
    "    ax.bar(np.arange(1,7), np.histogram(green(n,p), normed=True, bins=range(1,8))[0],\n",
    "           zs=2, zdir='y', alpha=0.8, color='green', label='P(2)')\n",
    "\n",
    "    ax.legend();\n",
    "    \n",
    "    ax.set(yticks=np.arange(1,4), yticklabels=['P(2 | G)', 'P(2)', 'P(2 | B)'])\n",
    "\n",
    "slider = widgets.FloatSlider(min=0, max=1, step=0.05, value=0.5)\n",
    "widgets.interactive(plot_machine, p=slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  This should provide some intuition for an expression of a 'joint' probability:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large P(H,E) = P(H \\mid E) \\cdot P(E)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seem reasonable to assume that $P(H,E) = P(E, H)$, so we can write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large P(H \\mid E) \\cdot P(E) = P(E \\mid H) \\cdot P(H) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving both sides by $P(E)$ we get the famous Bayes' rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large P(H \\mid E) = \\dfrac{P(E \\mid H) \\cdot P(H)}{P(E)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "### ¤ Probabilities are non negative and sum up to 1\n",
    "### ¤ Joint probability can be writen as a product of conditional and marginal probabilities\n",
    "### ¤ Bayes theorem *is a theorem* and follows from simple algebra\n",
    "### ¤ Sometimes we can check our probabilistic intuitions with the numpy.random module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Graphs with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We want to create a directed graph. Despite being based on the networkx, pgmpy - the target library of the \n",
    "# talk - doesn't really make use of a lot of nx functionality, besides plotting capacities. Networkx is a fun\n",
    "# and mature library, I really encourage you to read the documentation and play around with it a bit, because\n",
    "# this really doesn't do it justice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DiGraph stands for 'directed graph', to create and undirected graph skeleton, simply call 'nx.Graph'.\n",
    "g = nx.DiGraph()\n",
    "\n",
    "# If you add an edge with a node that doesn't not yet exist, the node is automatically added to the graph.\n",
    "g.add_edges_from([('Burglar', 'Dog'), ('Burglar','Alarm'), ('Earthquake', 'Alarm'), ('Alarm','Police')])\n",
    "\n",
    "# In fact you could do this directly with the initialization of a DiGraph object, simply by passing the same\n",
    "# array of tuples representing the edges to the nx.DiGraph() function:\n",
    "# nx.DiGraph([('Burglar', 'Dog'), ('Burglar','Alarm'), ('Earthquake', 'Alarm'), ('Alarm','Police')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's really handy to specify a dictionary with nodes as keys and tuples of x and y coordinates as values:\n",
    "\n",
    "positions={'Burglar':(2,6), 'Earthquake':(4,6), 'Alarm':(3,4), 'Dog':(1.5,3), 'Police':(3,1)}\n",
    "\n",
    "# The dict can then be passed as an argument of 'pos' parameter to the function:\n",
    "\n",
    "nx.draw_networkx(g, node_color='pink', node_size=15**3, font_size=20, arrowsize=40,pos=positions)\n",
    "\n",
    "\n",
    "# nx.draw* functions rely on the matplotlib.pyplot, so we can use the functionality of the latter as well -\n",
    "# for instance to save our figure to an external file!\n",
    "\n",
    "plt.savefig('test.png');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External visualization and saving graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For this to work you need to have installed GraphViz and python interface pygraphviz. We convert the graph \n",
    "# to a pygraphviz AGraph class instance to utilize the functionality of GraphViz. There are other admissible\n",
    "# values to pass as arguments to the 'prog' parameter, that will results in a different layout of the graph.\n",
    "# I picked 'dot' because I liked how it this specific graph was plotted.\n",
    "\n",
    "nx.drawing.nx_agraph.to_agraph(g).draw('graph.png', prog='dot')\n",
    "Image('graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two nodes with an edge between them are called 'adjacent', hence the name of the most common matrix \n",
    "# representation of a graph structure. There's a lot of other formats you can get the adjacency matrix,\n",
    "# but there's only one Pandas. \n",
    "\n",
    "a = nx.to_pandas_adjacency(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personally much preferred matrix representation when it's meant for human eyes.\n",
    "\n",
    "nx.to_pandas_edgelist(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can create a graph by passing an adjacency matrix as an argument to the init function. \n",
    "\n",
    "f = nx.DiGraph(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian networks with pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pgmpy stand for 'probabilistic graphical models using Python'\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "import pgmpy.inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always handy to look at the desired graph every once and then.\n",
    "\n",
    "Image('graph.png')\n",
    "#Image('test.png', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adding probabilities to graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The initialization is similar to the one of nx graphs, here we just pass an iterator of edges from g\n",
    "\n",
    "bn = BayesianModel([('Burglar', 'Dog'), ('Burglar','Alarm'), ('Earthquake', 'Alarm'), ('Alarm','Police')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to associate some probabilities with the graph, because BN are *probabilistic* models. We do so by \n",
    "# first creating a TabularCPD object for each of the nodes. Notice how all of my assumptions are just laid out\n",
    "# in the open and ready to be scrutinized. This is a general hallmark of Bayesian models - it's all about \n",
    "# being explicit! \n",
    "\n",
    "# CPD stands for conditional probability distribution. It takes some time to get used to the way this objects \n",
    "# are constructed. I found it good to just print the thing and tweak it some more until I see the things are \n",
    "# the way I want them to be.\n",
    "\n",
    "# Example: the way to read the first column is that the probability of Alarm variable being 0 and 1, conditional\n",
    "# on the variables Earthquake and Burglar, are 0.98 and 0.02, respectively. In general, we need to specify the\n",
    "# conditional probability for every value of the target variable for all the conditional probabilities defined\n",
    "# by the possible combinations of its 'parent' variables (the variables from which there are direct arrows to \n",
    "# the target variable).\n",
    "\n",
    "# I assumed that all the variables have only two values (0 and 1) - where 0 stands for no occurrence and 1 \n",
    "# stands for occurrence. So variable Alarm = 1 means that the alarm went off. But this is not necessarly the \n",
    "# case, we could easily have variable_card=4 evidence_card=[3,2] meaning that there are 4 possible values for \n",
    "# Alarm variable, 3 for Earthquake and 2 for Burglar. In this case we would need to pass a 4x6 array to the \n",
    "# values parameter. \n",
    "\n",
    "# One last thing to notice is that all the columns sum up to one. Think of it this way - when we're talking\n",
    "# about conditional probabilities, we're talking about how the probabilitiy would be distributed given that \n",
    "# certain conditions would hold. But the probability would still be a probability, and thus it has to sum up\n",
    "# to 1. In fact, this is already a simple way to slightly reduce the number of parameters we need to specify,\n",
    "# namely if we have a target variable that can take n different values, we only need to specify (n-1) different\n",
    "# values for every condition (combination of values of its parent nodes), because we can simply infer the last\n",
    "# value by substracting the rest of the values in that column from 1. More mature libraries do in fact use this\n",
    "# and all kinds of other optimizations, based on the probability calculus, such that the number of parameters\n",
    "# the end user needs to specify is greatly reduced.\n",
    "\n",
    "cpd_Alarm = TabularCPD('Alarm', variable_card=2, \n",
    "                    values=[\n",
    "                        [0.98, 0.3, 0.4, 0.1],\n",
    "                        [0.02, 0.7, 0.6, 0.9]\n",
    "                    ], \n",
    "                    evidence= ['Earthquake', 'Burglar'],\n",
    "                    evidence_card=[2, 2])\n",
    "print(cpd_Alarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Expand these TabularCPD objects, preferably each in its own cell, to see the assumptions I made when I was \n",
    "# specifying the network. Play around with it and see how different observation affect the other variables.\n",
    "\n",
    "cpd_Police = TabularCPD('Police', variable_card=2, values=[[0.95, 0.02], [0.05, 0.98]], evidence=['Alarm'], evidence_card=[2])\n",
    "cpd_Burglar = TabularCPD('Burglar', variable_card=2, values=([[0.5,0.5]]))\n",
    "cpd_Earthquake = TabularCPD('Earthquake', variable_card=2, values=([[0.5,0.5]]))\n",
    "cpd_Dog = TabularCPD('Dog', variable_card=2, values=([[0.8, 0.1], [0.2, 0.9]]), evidence=['Burglar'], evidence_card=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We associate the probabilities we defined with TabularCPD objects to the graph structure is simply by\n",
    "# calling the .add_cpds method of the BayesianModel object we created before:\n",
    "\n",
    "bn.add_cpds(cpd_Police, cpd_Earthquake, cpd_Alarm, cpd_Burglar, cpd_Dog)\n",
    "\n",
    "# If you'll re-run this cell multiple times, you'll get a warning for every CPD you'll be rewritting, don't\n",
    "# get scared the capital letters, you did nothing wrong!\n",
    "\n",
    "# Once you've associated the cpds with the BN, you might want to check that all the probability distributions\n",
    "# are properly defined. You can do this with the .check_model() method. If everything is ok, it returns True,\n",
    "# and throws an error otherwise. Play around - change the probabilities so that the columns don't sum up to one\n",
    "# or don't add cpd for a node you have in your skeleton BN and run this function to see what happens.\n",
    "\n",
    "bn.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can always print the TabularCPD object to see what it looks like. But maybe you forgot the name you used\n",
    "# or it was defined by somebody else. What you want to do then is to use the .get_cpds() method and just pass \n",
    "# to it the name of the variable you're interested in.\n",
    "\n",
    "print(bn.get_cpds('Dog'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you just call the method without passing a specific name of a node, you'll get a list of all cpds.\n",
    "\n",
    "type(bn.get_cpds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As said, it's always nice, to remind ourselfs what the graph looks like! That's the beauty of pgms, they're\n",
    "# highly interpretable (at least at a moderate scale), and easy to inspect visually.\n",
    "\n",
    "Image('graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To do some inference with the BN we just created we have to create a new object by calling a function from \n",
    "# pgmpy.inference and passing our model as an argument. This object can then be used to reason with the BN.\n",
    "# Variable elimination is an algorithm for *exact* computation of posterior probability and has exponential\n",
    "# time complexity - however, it simple to use and works good for small BN like our toy model.\n",
    "\n",
    "inference = pgmpy.inference.VariableElimination(bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Say we observe the police came to our house and we're interested in what's the probability that this is due to\n",
    "# the earthquake causing the alarm to go off. Remember how we encoded our variables - Police=1 is our 'data'.\n",
    "# We pass the list of variables we're interested in to variables parameter. Our observations are encoded as a\n",
    "# dictionary with variables as keys and the associated dict values corresponding to the variable values we have\n",
    "# observed. Play around with this function even before we investigate its returned value. Can you pass any \n",
    "# variable to the first parameter? What constraints apply to the dict passed to the evidence parameter?\n",
    "\n",
    "new_probs = inference.query(variables=['Earthquake'], evidence={'Police': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the inference object returns is a dictionary, with keys being the names of the variables we specified in\n",
    "# the query method call, linked to the 'posterior' probabilities associated with them, after fixed observations.\n",
    "\n",
    "type(new_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_probs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_probs['Earthquake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare this to the prior probability of Earthquake variable:\n",
    "\n",
    "print(bn.get_cpds('Earthquake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if in addition to observing police in front of our house we also hear our dog bark? Try to \n",
    "# convince yourself this is (at least qualitatively) correct result. Why is there a change in the posteriors?\n",
    "\n",
    "print(inference.query(['Earthquake'], evidence={'Police':1, 'Dog': 1})['Earthquake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three basic structures and independences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(bn.subgraph(['Alarm', 'Earthquake', 'Burglar']),\n",
    "                 pos=positions, node_size=15**3, node_color='pink', font_size=20, arrowsize=40)\n",
    "\n",
    "plt.title('COLLIDER STRUCTURE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we know that there was burglary, this doesn't tell us anything about there being an earthquake, and vice \n",
    "# versa. However, if we know there was an alarm we will consider earthquake to be more likely, then if we also\n",
    "# knew there was a burglary. Parent nodes in a colider structure are said to be conditionally dependent on the \n",
    "# common descendant. Police comming would also suffice to make them dependent, because the information flows \n",
    "# back to the alarm node. That is why when we provided additional evidence for there being a burglar (e.g. we\n",
    "# we observed dog barking), we indirectly provided evidence against there being an earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(bn.subgraph(['Alarm', 'Earthquake', 'Police']),\n",
    "                 pos=positions, node_size=15**3, node_color='pink', font_size=20, arrowsize=40)\n",
    "\n",
    "plt.title('CHAIN STRUCTURE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we know there is an earthquake we'll probably expect police to come more than if there's no earthquake. \n",
    "# However if we hear the alarm while walking on the street, we imagine the police is probably on already the  \n",
    "# way, no matter if we shortly after notice that there's an earthquake. If we know the status of the alarm,\n",
    "# observing the status of the earthquake is not informative of the police coming or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(bn.subgraph(['Dog', 'Alarm', 'Burglar']),\n",
    "                 pos=positions, node_size=15**3, node_color='pink', font_size=20, arrowsize=40)\n",
    "\n",
    "plt.title('COMMON CAUSE STRUCTURE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we hear the alarm we will likely expect the dog to start barking, more than if we don't hear it go off. \n",
    "# However if we see a burglar we're really condfident that the dog will bark, regardles of whether we hear\n",
    "# the alarm or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to check whether the two variables are *unconditionally* dependent is by calling the BayesianModel \n",
    "# method is_active_trail(). In words, if the trail is active (return True), then there's 'information flow' \n",
    "# from start to end node. This means that knowing something about one of the nodes, will be informative of the\n",
    "# possible state of the other - e.g. nodes are dependent. \n",
    "\n",
    "# Note that we could switch the start and the end node - information always flows in both directions.\n",
    "\n",
    "bn.is_active_trail(start='Earthquake', end='Burglar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check for *conditional* dependence as well, by passing a list of observed variables to the function.\n",
    "# If the function returns True, then knowing something about the observed variable establishes (or at least\n",
    "# doesn't cut) the information flow between the start and the end node. \n",
    "\n",
    "# Note that the actual value observed doesn't matter - any kind of information will (or will not) do. \n",
    "\n",
    "bn.is_active_trail(start='Earthquake', end='Burglar', observed=['Police'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference of independences that follow from the graph specification is computationally well studied and \n",
    "# there's plenty of literature (try to read something about 'd-separation'), but for now, we'll treat it as\n",
    "# a black box feature of the pgmpy. \n",
    "\n",
    "# The way to get all the independences that hold between the variables in a BayesianModel object is to simply\n",
    "# call the .get_independences() method.\n",
    "\n",
    "# The way to read 'X _|_ Y | Z' is that X is conditionally independent of Y if we know Z. In terms of active \n",
    "# trails - if we observe Z there is no information flow between X and Y. Now, it may very well be that also\n",
    "# 'X _|_ Y' holds by itself, meaning that X and Y are (unconditionally) independent, that is, if nothing is\n",
    "# observed there's no information flow (active trail) between X and Y.\n",
    "\n",
    "bn.get_independencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A way to express 'stochastic' independence of two variables $X,Y$ is to state that knowing the value of one doesn't tell you anything about another:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large X \\perp Y \\;\\; \\Rightarrow \\;\\; P(X\\mid Y) = P(X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This can be generalized to speak about **conditional** independence:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large X \\perp Y \\mid Z \\;\\; \\Rightarrow \\;\\; P(X \\mid Y, Z) = P(X \\mid Z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### In fact, every Bayesian network is required to satisfy a specific condition called *Parental Markov condition* (PMC). It simply states, that the probability distribution we use to define the relationships between the variables in the graph, must be such that each variable is independent of its non-descendants given its parent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For instance, regarding the graph above, Alarm is independent of Dog given Earthquake and Burglar. The latter\n",
    "# two are the parent nodes of Alarm (there's a direct edge from both of them to the Alarm variable). Moreover,\n",
    "# Dog is a non-descendant of the Alarm, because there's no way to follow the direction of edges to traverse the\n",
    "# graph from Alarm to Dog. However, because we can do so for Police, we say that the Police is a descendant of \n",
    "# the Alarm node (in fact the only one in our BN). Thus, even if we are given the values of Alarm's parent nodes\n",
    "# Alarm and Police are still dependent variables. \n",
    "\n",
    "# Root nodes - that are the nodes without parents (in our graph Earthquake and Burglar) are unconditionally \n",
    "# independent of all of their non-descendants. We can say that the parents of a root node is just an empty set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relying on the specifics of the representation allows for efficient way of computation. For instance, because of the PMC we calculate the joint probability of the whole graph with nodes $X_i$ by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large \\prod_i P(X_i \\mid Parents(X_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The above is just a short notation for multiplying all the terms of conditional probability for a node, \n",
    "# conditioned on its parent. For root nodes this term is just their 'prior' or marginal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the initials to abbreviate the names of the nodes (except for Police we'll use 'C', to avoid confusion with the probability function P). For our toy BN the above expression would translate into:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\Large P(A, B, C, D, E) = P(D\\mid B) \\cdot P(A \\mid B,E) \\cdot P(C \\mid A) \\cdot P(B) \\cdot P(E)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Of course this has to be done for all the possible values of each of the variable. Because we assumed each\n",
    "# node only has two possible values that would result in 2**5 terms to fully (and explicitly) specify the joint\n",
    "# probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning with random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When we define probabilities, we define them for a specific context. This context is often called 'experimental space' or 'sample space' and is denoted with $\\Omega$. It is essentially a set of *all* possible outcomes of an experiment (relative to how the experiment is defined), e.g.: \n",
    "\n",
    "### ¤ Rolling a 6-faced die: $\\; \\Omega$ = {1,2,3,4,5,6} or $\\Omega$ = {even, odd}\n",
    "### ¤ Flipping a coin: $\\; \\Omega$ = {Heads, Tails}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we'll make use of special *functions* called 'random variables', that assign a (real) number to every element of an experimental space:  \n",
    "\n",
    "$$\\Large X: \\Omega \\mapsto \\mathbb{R}$$\n",
    "\n",
    "### Now we can talk about the probability of a r.v. 'spitting out' a certain value, *e.g.* $\\; P(X = x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can see that we've been working with random variables more or less all the time. Specifically we made \n",
    "# use of so-called 'indicator' random variables. An indicator random variable, call it I, only has two values, \n",
    "# 0 and 1. If the event that is indicated by I happens, then I = 1, otherwise I = 0. To ask what's the\n",
    "# probability of that event not occuring is therefore to ask what's the value of P(I=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All of what we stated above still holds, probabilities we assign to different values of a given random \n",
    "# variable have to sum up to one and have to be non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can make use of the fact that random variable, despite their misleading name, are *functions* to derive\n",
    "# another very important law in the probability theory. The so-called LAW OF TOTAL PROBABILITY (LTP):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we know $X=x$, the probabilities of $Y=y$ might change, i.e. $P(Y=y) \\neq P(Y=y\\mid X=x)$, but they still have to sum up to 1. Hence,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\Large\n",
    "\\begin{align*}\n",
    "P(X=x) &= P(X=x) \\cdot 1 \\\\ \n",
    "& \\\\\n",
    "&= P(X=x) \\cdot \\sum_y P(Y=y \\mid X = x) \\\\\n",
    "& \\\\\n",
    "&= \\sum_y P(X=x) \\cdot P(Y = y \\mid X = x) \\\\\n",
    "& \\\\\n",
    "&= \\sum_y P(X=x, Y=y) \\\\\n",
    "& \\\\\n",
    "&= \\sum_y P(X=x \\mid Y=y) \\cdot P(Y=y)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, we could do this also without random variables, and in fact, the derivation you'll often see in the \n",
    "# literature will probably use sets or propositions. However, if we do so, we have to explicitly assume some\n",
    "# more conditions, that come for free with random variables, just because that's the way they're defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying this is what is often called 'integrating out' or 'marginalization'. It is useful because we can\n",
    "# always get rid of a variable from an expression for a joint probability, simply by pluggin in all of its \n",
    "# values and summing the number up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Even more importantly, now we can see why we only need to specify prior probabilities for the root nodes \n",
    "# and conditional probabilities for the rest. Because those are already sufficient to get the marginal (prior)\n",
    "# probabilities of other nodes, simply by applying the LTP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can also rewrite the Bayes theorem for random variables, and show that we only need to have prior belief about the 'hypothesis' variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large \n",
    "\\begin{align*}\n",
    "P(H=h \\mid E=e) &= \\dfrac{P(E = e \\mid H=h) \\cdot P(H = h)}{P(E = e)} \\\\\n",
    "& \\\\\n",
    "&=  \\dfrac{P(E = e \\mid H=h) \\cdot P(H = h)}{\\sum_h P(E = e, H=h)} \\\\\n",
    "& \\\\\n",
    "&=  \\dfrac{P(E = e \\mid H=h) \\cdot P(H = h)}{\\sum_h P(E = e \\mid H=h) \\cdot P(H=h)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning with the BN structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Say that there we hear the dog bark and now we want to feed this information into our Bayesian network. Just by expression of conditional  probability alone, we would have to calculate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large \\begin{align*}\n",
    "P_{new}(A, E, B, C) &= P(A, E, B, C \\mid D=1) \\\\\n",
    "&\\\\\n",
    "&= \\dfrac{P(A, E, B, C, D=1)}{P(D=1)} \\\\\n",
    "&\\\\\n",
    "&= \\dfrac{P(A, E, B, C, D=1)}{\\sum_{a,e,b,c} P(A, E, B, C, D=1)} \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But because of the structure of the Bayesian network, we know that PMC implies that $D$ is independent of its nondescendants $(E,A,C)$, given its parent $(B)$, so the above simplifies to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large P_{new}(A, E, B, C) = \\dfrac{P(A, E, B, C, D=1)}{\\sum_{b} P(D=1 \\mid B=b) \\cdot P(B=b)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
